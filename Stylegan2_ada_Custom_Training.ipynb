{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Stylegan2_ada_Custom_Training.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Stylegan2_ada_Custom_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"cPI5E5y0pujD"},"source":["# Custom Training StyleGan2-ADA"]},{"cell_type":"markdown","metadata":{"id":"SI_i1MwgpzOD"},"source":["StyleGAN2-ADA only work with Tensorflow 1. Run the next cell before anything else to make sure we’re using TF1 and not TF2."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZXMA1LGPv6L","executionInfo":{"status":"ok","timestamp":1616925134727,"user_tz":-120,"elapsed":19754,"user":{"displayName":"Adam Siemaszkiewicz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkDjVXI1qcBXrxIR5B85831M3tmlZou2jukYc-A=s64","userId":"16676861624055550812"}},"outputId":"89aa180f-4738-41fa-e4cd-4a9ae6b730fe"},"source":["# mount Google Drive on the runtime\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ig5hqcirQ5ka","executionInfo":{"status":"ok","timestamp":1616925138560,"user_tz":-120,"elapsed":831,"user":{"displayName":"Adam Siemaszkiewicz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkDjVXI1qcBXrxIR5B85831M3tmlZou2jukYc-A=s64","userId":"16676861624055550812"}},"outputId":"bffc2fa6-2e4c-496c-ec7f-7bcb315f5b29"},"source":["# create a symbolic link to a working directory\n","!ln -s /content/gdrive/My\\ Drive/Colab\\ Notebooks/monixypAI /mydrive\n","\n","# navigate to the working directory\n","%cd /mydrive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/monixypAI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKYAU7Wub3WW","executionInfo":{"status":"ok","timestamp":1616925139268,"user_tz":-120,"elapsed":793,"user":{"displayName":"Adam Siemaszkiewicz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkDjVXI1qcBXrxIR5B85831M3tmlZou2jukYc-A=s64","userId":"16676861624055550812"}},"outputId":"922fca39-8aba-4ba8-b84e-7a22905ca59e"},"source":["%tensorflow_version 1.x"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51ei6d5kxVDm","executionInfo":{"status":"ok","timestamp":1616925140267,"user_tz":-120,"elapsed":1203,"user":{"displayName":"Adam Siemaszkiewicz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkDjVXI1qcBXrxIR5B85831M3tmlZou2jukYc-A=s64","userId":"16676861624055550812"}},"outputId":"65401a07-97c9-4d31-bdf7-83ec386d4602"},"source":["!nvidia-smi"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Sun Mar 28 09:52:21 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5YcUMPQp6ipP"},"source":["## Install Repo to Google Drive\n","\n","Colab is a little funky with training. I’ve found the best way to do this is to install the repo directly into your Google Drive folder.\n","\n","First, mount your Drive to the Colab notebook: "]},{"cell_type":"code","metadata":{"id":"pxxYlEKI9Gis"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epV6TDzAjox1"},"source":["Next, run this cell. If you’re already installed the repo, it will skip the installation process and change into the repo’s directory. If you haven’t installed it, it will install all the files necessary."]},{"cell_type":"code","metadata":{"id":"8HX77jscX2zV"},"source":["# import os\n","# if os.path.isdir(\"/mydrive/stylegan2-ada\"):\n","#     %cd \"/mydrive/stylegan2-ada\"\n","# else:\n","#     #install script\n","#     %cd \"/mydrive/\"\n","#     !git clone https://github.com/dvschultz/stylegan2-ada\n","#     %cd stylegan2-ada\n","#     !mkdir downloads\n","#     !mkdir datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7oj_kBaemol"},"source":["# !git config --global user.name \"test\"\n","# !git config --global user.email \"test@test.com\"\n","# !git fetch origin\n","# !git checkout origin/main -- train.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeS9tDvt61VG"},"source":["## Convert dataset to .tfrecords"]},{"cell_type":"markdown","metadata":{"id":"_Q58MJbckLUc"},"source":["**Note: You only need to do this once per dataset. If you have already run this and are returning to conntinue training, skip these cells.**\n","\n","Next we need to convert our image dataset to a format that StyleGAN2-ADA can read from. There are two options here. You can upload your dataset directly to Colab (as a zipped file), or you can upload it to Drive directly and read it from there."]},{"cell_type":"code","metadata":{"id":"8JUP51nJdEjz"},"source":["# #if you manually uploaded your dataset to Colab, unzip it\n","# zip_path = \"/mydrive/stylegan2-ada/datasets/combined.zip\"\n","\n","# !unzip {zip_path} -d /mydrive/stylegan2-ada/datasets/monixyp/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9dkxOzJ6TlVr"},"source":["# from PIL import Image\n","# PATH = '/mydrive/stylegan2-ada/datasets/monixyp/'\n","# SIZE = (1024, 1024)\n","# for n, file in enumerate(os.listdir(PATH)):\n","#   image = Image.open(PATH+file) \\\n","#                .convert('RGB') \\\n","#                .resize(SIZE)\n","#   image.save(PATH+f'{n}.jpeg', 'jpeg')\n","#   os.remove(PATH+file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whPbpKChTkTe"},"source":["# os.listdir('/mydrive/stylegan2-ada/datasets/monixyp/')\n","# !ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D0QH0nzjlbEE"},"source":["Now that your image dataset is uploaded, we need to convert it to the `.tfrecords` format.\n","\n","Depending on the resolution of your images and how many you have, this can take a while."]},{"cell_type":"code","metadata":{"id":"w7PnTx9SZOpN"},"source":["# !python train.py --help "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-BZHhBe7AvO"},"source":["# %cd '/mydrive/stylegan2-ada/'\n","\n","# #update this to the path to your image folder\n","# dataset_path = '/mydrive/stylegan2-ada/datasets/monixyp/'\n","# #give your dataset a name\n","# dataset_name = 'monixyp_tfrecords'\n","\n","# #you don't need to edit anything here\n","# !python dataset_tool.py create_from_images ./datasets/{dataset_name} {dataset_path}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8DvTupHzP2s_"},"source":["## Train a custom model\n","\n","We’re ready to start training! There are numerous arguments to training, what’s listed below are the most popular options. To see all the options, run the following cell."]},{"cell_type":"code","metadata":{"id":"Fxu7CA0Qb1Yd"},"source":["# !python train.py --help"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhGxmOr6d_1W"},"source":["# !ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOftFoyiDU3s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616961107090,"user_tz":-120,"elapsed":25820579,"user":{"displayName":"Adam Siemaszkiewicz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjHkDjVXI1qcBXrxIR5B85831M3tmlZou2jukYc-A=s64","userId":"16676861624055550812"}},"outputId":"d3df920a-8353-41df-fcde-3bb841abc634"},"source":["%cd '/mydrive/stylegan2-ada/'\n","\n","#this name must EXACTLY match the dataset name you used when creating the .tfrecords file\n","dataset_name = 'monixyp_tfrecords'\n","#how often should the model generate samples and a .pkl file\n","snapshot_count = 1\n","#should the images be mirrored left to right?\n","mirrored = True\n","#should the images be mirrored top to bottom?\n","mirroredY = True\n","#metrics? \n","metric_list = None\n","#augments\n","#bgcfnc enables all available augmentations (blit, geom, color, filter, noise, cutout).\n","augs = 'bg'\n","\n","#\n","# this is the most important cell to update\n","#\n","# running it for the first time? set it to ffhq(+resolution)\n","# resuming? get the path to your latest .pkl file and use that\n","# resume_from = \"/content/drive/My\\ Drive/colab-sg2-ada2/stylegan2-ada/results/00008-dante1024-mirror-mirrory-11gb-gpu-bg-resumecustom/network-snapshot-000160.pkl\"\n","\n","resume_from = '/mydrive/stylegan2-ada/results/00025-monixyp_tfrecords-mirror-mirrory-11gb-gpu-bg-resumecustom/network-snapshot-000072.pkl'\n","\n","#don't edit this unless you know what you're doing :)\n","!python train.py --outdir ./results \\\n","                 --snap={snapshot_count} \\\n","                 --cfg=11gb-gpu \\\n","                 --data=./datasets/{dataset_name} \\\n","                 --augpipe={augs} \\\n","                 --mirror={mirrored} \\\n","                 --mirrory={mirroredY} \\\n","                 --metrics={metric_list} \\\n","                 --resume={resume_from}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/monixypAI/stylegan2-ada\n","tcmalloc: large alloc 4294967296 bytes == 0x560e2a066000 @  0x7f9bbef07001 0x7f9bbc10a54f 0x7f9bbc15ab58 0x7f9bbc15eb17 0x7f9bbc1fd203 0x560e21d840e4 0x560e21d83de0 0x560e21df86f5 0x560e21df2e0d 0x560e21d8602c 0x560e21dc6d39 0x560e21dc3c84 0x560e21d848e9 0x560e21df8ade 0x560e21df2b0e 0x560e21cc4e2b 0x560e21df51e6 0x560e21df2b0e 0x560e21cc4e2b 0x560e21df51e6 0x560e21df2e0d 0x560e21cc4e2b 0x560e21df51e6 0x560e21d8569a 0x560e21df3a45 0x560e21df2b0e 0x560e21df2813 0x560e21ebc592 0x560e21ebc90d 0x560e21ebc7b6 0x560e21e94103\n","tcmalloc: large alloc 4294967296 bytes == 0x560f2a066000 @  0x7f9bbef051e7 0x7f9bbc10a46e 0x7f9bbc15ac7b 0x7f9bbc15b35f 0x7f9bbc1fd103 0x560e21d840e4 0x560e21d83de0 0x560e21df86f5 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21d8569a 0x560e21df3a45 0x560e21df2b0e 0x560e21d8577a 0x560e21df7e50 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21df2e0d 0x560e21d8602c 0x560e21dc6d39 0x560e21dc3c84 0x560e21d848e9 0x560e21df8ade\n","tcmalloc: large alloc 4294967296 bytes == 0x56102b376000 @  0x7f9bbef051e7 0x7f9bbc10a46e 0x7f9bbc15ac7b 0x7f9bbc15b35f 0x7f9b67b0a235 0x7f9b6748d792 0x7f9b6748dd42 0x7f9b67446aee 0x560e21d83fd7 0x560e21d83de0 0x560e21df8244 0x560e21d8569a 0x560e21df3c9e 0x560e21df2e0d 0x560e21cc4eb0 0x560e21df51e6 0x560e21df2b0e 0x560e21d8577a 0x560e21df3c9e 0x560e21df2e0d 0x560e21d8577a 0x560e21df3c9e 0x560e21d8569a 0x560e21df3c9e 0x560e21df2b0e 0x560e21d85e11 0x560e21d86231 0x560e21df51e6 0x560e21df2b0e 0x560e21d8577a 0x560e21df3a45\n","\n","Training options:\n","{\n","  \"G_args\": {\n","    \"func_name\": \"training.networks.G_main\",\n","    \"fmap_base\": 16384,\n","    \"fmap_max\": 512,\n","    \"mapping_layers\": 8,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"D_args\": {\n","    \"func_name\": \"training.networks.D_main\",\n","    \"mbstd_group_size\": 4,\n","    \"fmap_base\": 16384,\n","    \"fmap_max\": 512,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_opt_args\": {\n","    \"beta1\": 0.0,\n","    \"beta2\": 0.99,\n","    \"learning_rate\": 0.002\n","  },\n","  \"D_opt_args\": {\n","    \"beta1\": 0.0,\n","    \"beta2\": 0.99,\n","    \"learning_rate\": 0.002\n","  },\n","  \"loss_args\": {\n","    \"func_name\": \"training.loss.stylegan2\",\n","    \"r1_gamma\": 10\n","  },\n","  \"augment_args\": {\n","    \"class_name\": \"training.augment.AdaptiveAugment\",\n","    \"tune_heuristic\": \"rt\",\n","    \"tune_target\": 0.6,\n","    \"apply_func\": \"training.augment.augment_pipeline\",\n","    \"apply_args\": {\n","      \"xflip\": 1,\n","      \"rotate90\": 1,\n","      \"xint\": 1,\n","      \"scale\": 1,\n","      \"rotate\": 1,\n","      \"aniso\": 1,\n","      \"xfrac\": 1\n","    },\n","    \"tune_kimg\": 100\n","  },\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 1,\n","  \"network_snapshot_ticks\": 1,\n","  \"train_dataset_args\": {\n","    \"path\": \"./datasets/monixyp_tfrecords\",\n","    \"max_label_size\": 0,\n","    \"use_raw\": false,\n","    \"resolution\": 1024,\n","    \"mirror_augment\": true,\n","    \"mirror_augment_v\": true\n","  },\n","  \"metric_arg_list\": [],\n","  \"metric_dataset_args\": {\n","    \"path\": \"./datasets/monixyp_tfrecords\",\n","    \"max_label_size\": 0,\n","    \"use_raw\": false,\n","    \"resolution\": 1024,\n","    \"mirror_augment\": true,\n","    \"mirror_augment_v\": true\n","  },\n","  \"total_kimg\": 25000,\n","  \"minibatch_size\": 4,\n","  \"minibatch_gpu\": 4,\n","  \"G_smoothing_kimg\": 10,\n","  \"G_smoothing_rampup\": null,\n","  \"resume_pkl\": \"/mydrive/stylegan2-ada/results/00025-monixyp_tfrecords-mirror-mirrory-11gb-gpu-bg-resumecustom/network-snapshot-000072.pkl\",\n","  \"run_dir\": \"./results/00026-monixyp_tfrecords-mirror-mirrory-11gb-gpu-bg-resumecustom\"\n","}\n","\n","Output directory:  ./results/00026-monixyp_tfrecords-mirror-mirrory-11gb-gpu-bg-resumecustom\n","Training data:     ./datasets/monixyp_tfrecords\n","Training length:   25000 kimg\n","Resolution:        1024\n","Number of GPUs:    1\n","\n","Creating output directory...\n","Loading training set...\n","tcmalloc: large alloc 4294967296 bytes == 0x560e29d64000 @  0x7f9bbef07001 0x7f9bbc10a54f 0x7f9bbc15ab58 0x7f9bbc15eb17 0x7f9bbc1fd203 0x560e21d840e4 0x560e21d83de0 0x560e21df86f5 0x560e21df2e0d 0x560e21d8602c 0x560e21dc6d39 0x560e21dc3c84 0x560e21d848e9 0x560e21df8ade 0x560e21df2b0e 0x560e21cc4e2b 0x560e21df51e6 0x560e21df2b0e 0x560e21cc4e2b 0x560e21df51e6 0x560e21df2e0d 0x560e21cc4e2b 0x560e21df51e6 0x560e21d8569a 0x560e21df3a45 0x560e21df2b0e 0x560e21df2813 0x560e21ebc592 0x560e21ebc90d 0x560e21ebc7b6 0x560e21e94103\n","tcmalloc: large alloc 4294967296 bytes == 0x56112b376000 @  0x7f9bbef051e7 0x7f9bbc10a46e 0x7f9bbc15ac7b 0x7f9bbc15b35f 0x7f9bbc1fd103 0x560e21d840e4 0x560e21d83de0 0x560e21df86f5 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21d8569a 0x560e21df3a45 0x560e21df2b0e 0x560e21d8577a 0x560e21df7e50 0x560e21df2b0e 0x560e21d8577a 0x560e21df486a 0x560e21df2e0d 0x560e21d8602c 0x560e21dc6d39 0x560e21dc3c84 0x560e21d848e9 0x560e21df8ade\n","tcmalloc: large alloc 4294967296 bytes == 0x56112b376000 @  0x7f9bbef051e7 0x7f9bbc10a46e 0x7f9bbc15ac7b 0x7f9bbc15b35f 0x7f9b67b0a235 0x7f9b6748d792 0x7f9b6748dd42 0x7f9b67446aee 0x560e21d83fd7 0x560e21d83de0 0x560e21df8244 0x560e21d8569a 0x560e21df3c9e 0x560e21df2e0d 0x560e21cc4eb0 0x560e21df51e6 0x560e21df2b0e 0x560e21d8577a 0x560e21df3c9e 0x560e21df2e0d 0x560e21d8577a 0x560e21df3c9e 0x560e21d8569a 0x560e21df3c9e 0x560e21df2b0e 0x560e21d85e11 0x560e21d86231 0x560e21df51e6 0x560e21df2b0e 0x560e21d8577a 0x560e21df3a45\n","Image shape: [3, 1024, 1024]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n","Resuming from \"/mydrive/stylegan2-ada/results/00025-monixyp_tfrecords-mirror-mirrory-11gb-gpu-bg-resumecustom/network-snapshot-000072.pkl\"\n","\n","G                               Params    OutputShape          WeightShape     \n","---                             ---       ---                  ---             \n","latents_in                      -         (?, 512)             -               \n","labels_in                       -         (?, 0)               -               \n","epochs                          1         ()                   ()              \n","epochs_1                        1         ()                   ()              \n","G_mapping/Normalize             -         (?, 512)             -               \n","G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n","G_mapping/Broadcast             -         (?, 18, 512)         -               \n","dlatent_avg                     -         (512,)               -               \n","Truncation/Lerp                 -         (?, 18, 512)         -               \n","G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n","G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n","G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n","G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n","G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n","G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n","G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n","G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n","G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n","G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n","G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n","G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n","G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n","G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n","G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n","G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n","G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n","G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n","G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n","G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n","G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n","---                             ---       ---                  ---             \n","Total                           30370062                                       \n","\n","\n","D                     Params    OutputShape          WeightShape     \n","---                   ---       ---                  ---             \n","images_in             -         (?, 3, 1024, 1024)   -               \n","labels_in             -         (?, 0)               -               \n","1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n","1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n","1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n","1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n","512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n","512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n","512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n","256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n","256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n","256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n","128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n","128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n","128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n","64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n","64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n","64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n","32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n","32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n","32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n","16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n","16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n","16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n","8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n","8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n","8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n","4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n","4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n","4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n","Output                513       (?, 1)               (512, 1)        \n","---                   ---       ---                  ---             \n","Total                 29012513                                       \n","\n","Exporting sample images...\n","Replicating networks across 1 GPUs...\n","Initializing augmentations...\n","Setting up optimizers...\n","Constructing training graph...\n","Finalizing training ops...\n","Initializing metrics...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 2m 57s       sec/tick 26.5    sec/kimg 1654.78 maintenance 150.1  gpumem 10.3  augment 0.000\n","tick 1     kimg 4.0      time 35m 13s      sec/tick 1920.5  sec/kimg 480.13  maintenance 15.9   gpumem 10.3  augment 0.035\n","tick 2     kimg 8.0      time 1h 07m 30s   sec/tick 1932.0  sec/kimg 483.00  maintenance 5.1    gpumem 10.3  augment 0.071\n","tick 3     kimg 12.0     time 1h 39m 55s   sec/tick 1940.0  sec/kimg 485.01  maintenance 4.4    gpumem 10.3  augment 0.107\n","tick 4     kimg 16.0     time 2h 12m 30s   sec/tick 1950.8  sec/kimg 487.70  maintenance 4.2    gpumem 10.3  augment 0.141\n","tick 5     kimg 20.0     time 2h 45m 09s   sec/tick 1955.7  sec/kimg 488.94  maintenance 4.1    gpumem 10.3  augment 0.178\n","tick 6     kimg 24.0     time 3h 17m 56s   sec/tick 1961.8  sec/kimg 490.45  maintenance 4.8    gpumem 10.3  augment 0.212\n","tick 7     kimg 28.0     time 3h 50m 48s   sec/tick 1968.0  sec/kimg 492.00  maintenance 4.2    gpumem 10.3  augment 0.247\n","tick 8     kimg 32.0     time 4h 23m 48s   sec/tick 1975.5  sec/kimg 493.87  maintenance 4.3    gpumem 10.3  augment 0.280\n","tick 9     kimg 36.0     time 4h 56m 51s   sec/tick 1978.6  sec/kimg 494.66  maintenance 4.2    gpumem 10.3  augment 0.312\n","tick 10    kimg 40.0     time 5h 29m 59s   sec/tick 1983.8  sec/kimg 495.94  maintenance 4.3    gpumem 10.3  augment 0.344\n","tick 11    kimg 44.0     time 6h 03m 10s   sec/tick 1986.8  sec/kimg 496.69  maintenance 4.2    gpumem 10.3  augment 0.376\n","tick 12    kimg 48.0     time 6h 36m 25s   sec/tick 1991.2  sec/kimg 497.81  maintenance 4.1    gpumem 10.3  augment 0.407\n","tick 13    kimg 52.0     time 7h 09m 47s   sec/tick 1997.2  sec/kimg 499.30  maintenance 4.1    gpumem 10.3  augment 0.439\n","tick 14    kimg 56.0     time 7h 43m 11s   sec/tick 2000.2  sec/kimg 500.04  maintenance 4.2    gpumem 10.3  augment 0.469\n","tick 15    kimg 60.0     time 8h 16m 38s   sec/tick 2003.3  sec/kimg 500.83  maintenance 4.2    gpumem 10.3  augment 0.499\n","tick 16    kimg 64.0     time 8h 50m 11s   sec/tick 2008.8  sec/kimg 502.21  maintenance 4.2    gpumem 10.3  augment 0.527\n","tick 17    kimg 68.0     time 9h 23m 47s   sec/tick 2011.8  sec/kimg 502.94  maintenance 4.2    gpumem 10.3  augment 0.556\n","tick 18    kimg 72.0     time 9h 57m 27s   sec/tick 2014.9  sec/kimg 503.72  maintenance 4.3    gpumem 10.3  augment 0.587\n","Traceback (most recent call last):\n","  File \"train.py\", line 645, in <module>\n","    main()\n","  File \"train.py\", line 637, in main\n","    run_training(**vars(args))\n","  File \"train.py\", line 522, in run_training\n","    training_loop.training_loop(**training_options)\n","  File \"/content/gdrive/My Drive/Colab Notebooks/monixypAI/stylegan2-ada/training/training_loop.py\", line 252, in training_loop\n","    tflib.run([G_train_op, data_fetch_op])\n","  File \"/content/gdrive/My Drive/Colab Notebooks/monixypAI/stylegan2-ada/dnnlib/tflib/tfutil.py\", line 33, in run\n","    return tf.get_default_session().run(*args, **kwargs)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lohotw1FqC54"},"source":["### While it’s training...\n","**Once the above cell is running you should be training!**\n","\n","Don’t close this tab! Colab needs to be open and running in order to continue training. Every ~15min or so a new line should get added to your output, indicated its still training. Depending on you `snapshot_count` setting you should see the results folder in your Google drive folder fill with both samples (`fakesXXXXXx.jpg`) and model weights (`network-snapshot-XXXXXX.pkl`). The samples are worth looking at while it trains but don’t get too worried about each individual sample.\n","\n","If you chose a metric, you will also see scores for each snapshot. Don’t obsess over these! they are a guide, it can go up or down slightly for each snapshot. What you want to see is a gradual lowering of the score over time.\n","\n","Once Colab shuts off, you can Reconnect the notebook and re-run every cell from top to bottom. Make sure you update the `resume_from` path to continue training from the latest model."]},{"cell_type":"code","metadata":{"id":"UZR4ireZE6JF"},"source":[""],"execution_count":null,"outputs":[]}]}